{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac8095fb",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-17T21:29:20.859305Z",
     "iopub.status.busy": "2025-04-17T21:29:20.859099Z",
     "iopub.status.idle": "2025-04-17T21:29:45.287760Z",
     "shell.execute_reply": "2025-04-17T21:29:45.286764Z"
    },
    "papermill": {
     "duration": 24.435249,
     "end_time": "2025-04-17T21:29:45.289009",
     "exception": false,
     "start_time": "2025-04-17T21:29:20.853760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 21:29:29.070697: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744925369.534211      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744925369.671111      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/customer-behavior-dataset/Customer_Behavior_Data.csv\n",
      "/kaggle/input/ps-dataset/order_data_last_six_month.xlsx - Worksheet.csv\n",
      "/kaggle/input/ps-dataset/associated_order_item_data_last_six_month.xlsx - Worksheet.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score,recall_score,f1_score,precision_score\n",
    "from tensorflow.keras.models import clone_model\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7e998cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T21:29:45.298639Z",
     "iopub.status.busy": "2025-04-17T21:29:45.298142Z",
     "iopub.status.idle": "2025-04-17T21:29:45.302501Z",
     "shell.execute_reply": "2025-04-17T21:29:45.301780Z"
    },
    "papermill": {
     "duration": 0.010156,
     "end_time": "2025-04-17T21:29:45.303665",
     "exception": false,
     "start_time": "2025-04-17T21:29:45.293509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.18.0\n",
      "Keras version: 3.5.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Keras version:\", keras.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "261f411e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T21:29:45.312425Z",
     "iopub.status.busy": "2025-04-17T21:29:45.311964Z",
     "iopub.status.idle": "2025-04-17T21:29:45.316977Z",
     "shell.execute_reply": "2025-04-17T21:29:45.316296Z"
    },
    "papermill": {
     "duration": 0.010428,
     "end_time": "2025-04-17T21:29:45.317979",
     "exception": false,
     "start_time": "2025-04-17T21:29:45.307551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def piechart(series):\n",
    "    \"\"\"\n",
    "    Automatically plots a pie chart from a Pandas Series.\n",
    "    - Uses the series name as the chart title.\n",
    "    - Displays value counts as percentages.\n",
    "    \"\"\"\n",
    "    if not isinstance(series, pd.Series):\n",
    "        raise TypeError(\"Input must be a pandas Series\")\n",
    "\n",
    "    counts = series.value_counts(dropna=False)\n",
    "    labels = counts.index.astype(str)\n",
    "    \n",
    "    # Auto-title using series name or fallback\n",
    "    title = series.name if series.name else \"Pie Chart\"\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.pie(counts, labels=labels, autopct='%1.1f%%', startangle=90, counterclock=False)\n",
    "    plt.title(title)\n",
    "    plt.axis('equal')  # Equal aspect ratio ensures the pie is circular\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa5b0d07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T21:29:45.326423Z",
     "iopub.status.busy": "2025-04-17T21:29:45.326153Z",
     "iopub.status.idle": "2025-04-17T21:29:45.363062Z",
     "shell.execute_reply": "2025-04-17T21:29:45.362334Z"
    },
    "papermill": {
     "duration": 0.043293,
     "end_time": "2025-04-17T21:29:45.364902",
     "exception": false,
     "start_time": "2025-04-17T21:29:45.321609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "beh_data=pd.read_csv(\"/kaggle/input/customer-behavior-dataset/Customer_Behavior_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "908d06ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T21:29:45.375193Z",
     "iopub.status.busy": "2025-04-17T21:29:45.374657Z",
     "iopub.status.idle": "2025-04-17T21:29:45.395048Z",
     "shell.execute_reply": "2025-04-17T21:29:45.394207Z"
    },
    "papermill": {
     "duration": 0.026712,
     "end_time": "2025-04-17T21:29:45.396479",
     "exception": false,
     "start_time": "2025-04-17T21:29:45.369767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "zero_people=beh_data[beh_data['Total Orders']<=4]['customer_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c74c5b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T21:29:45.405016Z",
     "iopub.status.busy": "2025-04-17T21:29:45.404808Z",
     "iopub.status.idle": "2025-04-17T21:29:45.411474Z",
     "shell.execute_reply": "2025-04-17T21:29:45.410884Z"
    },
    "papermill": {
     "duration": 0.011925,
     "end_time": "2025-04-17T21:29:45.412503",
     "exception": false,
     "start_time": "2025-04-17T21:29:45.400578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster_1_people=beh_data[((beh_data['Total Orders']<=25) & (beh_data['Total Orders']>4) & (beh_data['Average Order Gap Days']>=14))]['customer_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e05e490c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T21:29:45.420571Z",
     "iopub.status.busy": "2025-04-17T21:29:45.420375Z",
     "iopub.status.idle": "2025-04-17T21:29:45.430968Z",
     "shell.execute_reply": "2025-04-17T21:29:45.430185Z"
    },
    "papermill": {
     "duration": 0.015647,
     "end_time": "2025-04-17T21:29:45.432038",
     "exception": false,
     "start_time": "2025-04-17T21:29:45.416391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster_2_people = beh_data['customer_id'][~beh_data['customer_id'].isin(cluster_1_people) & ~beh_data['customer_id'].isin(zero_people)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0abf3cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T21:29:45.440147Z",
     "iopub.status.busy": "2025-04-17T21:29:45.439943Z",
     "iopub.status.idle": "2025-04-17T21:29:45.736040Z",
     "shell.execute_reply": "2025-04-17T21:29:45.735033Z"
    },
    "papermill": {
     "duration": 0.301814,
     "end_time": "2025-04-17T21:29:45.737754",
     "exception": false,
     "start_time": "2025-04-17T21:29:45.435940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset=pd.read_csv(\"/kaggle/input/ps-dataset/order_data_last_six_month.xlsx - Worksheet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64787ea7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T21:29:45.749113Z",
     "iopub.status.busy": "2025-04-17T21:29:45.748440Z",
     "iopub.status.idle": "2025-04-17T21:29:45.758899Z",
     "shell.execute_reply": "2025-04-17T21:29:45.758133Z"
    },
    "papermill": {
     "duration": 0.017225,
     "end_time": "2025-04-17T21:29:45.759985",
     "exception": false,
     "start_time": "2025-04-17T21:29:45.742760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data=dataset[dataset['customer_id'].isin(cluster_2_people)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11f1dfcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T21:29:45.768316Z",
     "iopub.status.busy": "2025-04-17T21:29:45.768062Z",
     "iopub.status.idle": "2025-04-17T21:29:45.791601Z",
     "shell.execute_reply": "2025-04-17T21:29:45.790835Z"
    },
    "papermill": {
     "duration": 0.029048,
     "end_time": "2025-04-17T21:29:45.792728",
     "exception": false,
     "start_time": "2025-04-17T21:29:45.763680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_date</th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_number</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_name</th>\n",
       "      <th>poc_name</th>\n",
       "      <th>poc_id</th>\n",
       "      <th>amount</th>\n",
       "      <th>discount</th>\n",
       "      <th>net_order_amount</th>\n",
       "      <th>profit</th>\n",
       "      <th>order_status</th>\n",
       "      <th>warehouse_name</th>\n",
       "      <th>warehouse_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03/04/2025</td>\n",
       "      <td>136349</td>\n",
       "      <td>SO/25-26/000818</td>\n",
       "      <td>5235</td>\n",
       "      <td>Anshu General Store Sector 34</td>\n",
       "      <td>Vikas Gupta</td>\n",
       "      <td>6</td>\n",
       "      <td>19125.00</td>\n",
       "      <td>1650.00</td>\n",
       "      <td>17475.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CLOSED</td>\n",
       "      <td>Noida</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30/01/2025</td>\n",
       "      <td>110393</td>\n",
       "      <td>SO/24-25/90881</td>\n",
       "      <td>7622</td>\n",
       "      <td>bhai di rasoi</td>\n",
       "      <td>Abhay Srimali</td>\n",
       "      <td>7814</td>\n",
       "      <td>9670.48</td>\n",
       "      <td>735.48</td>\n",
       "      <td>8935.0</td>\n",
       "      <td>-56.4</td>\n",
       "      <td>CLOSED</td>\n",
       "      <td>Greater NOIDA</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26/12/2024</td>\n",
       "      <td>96182</td>\n",
       "      <td>SO/24-25/77411</td>\n",
       "      <td>2223</td>\n",
       "      <td>Bikaner Sweets ( Harola )</td>\n",
       "      <td>Swatantra</td>\n",
       "      <td>25</td>\n",
       "      <td>4520.00</td>\n",
       "      <td>420.00</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>CLOSED</td>\n",
       "      <td>Noida</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30/12/2024</td>\n",
       "      <td>97858</td>\n",
       "      <td>SO/24-25/78975</td>\n",
       "      <td>6903</td>\n",
       "      <td>Lucknow kirana store</td>\n",
       "      <td>Raj Kumar</td>\n",
       "      <td>7039</td>\n",
       "      <td>1700.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>-88.0</td>\n",
       "      <td>CLOSED</td>\n",
       "      <td>Gomti Nagar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>04/01/2025</td>\n",
       "      <td>99588</td>\n",
       "      <td>SO/24-25/80618</td>\n",
       "      <td>2296</td>\n",
       "      <td>Champaran Meat House</td>\n",
       "      <td>Ajay Singh</td>\n",
       "      <td>38</td>\n",
       "      <td>5074.00</td>\n",
       "      <td>214.00</td>\n",
       "      <td>4860.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>CLOSED</td>\n",
       "      <td>Telibagh</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_date  order_id     order_number  customer_id  \\\n",
       "0  03/04/2025    136349  SO/25-26/000818         5235   \n",
       "1  30/01/2025    110393   SO/24-25/90881         7622   \n",
       "3  26/12/2024     96182   SO/24-25/77411         2223   \n",
       "4  30/12/2024     97858   SO/24-25/78975         6903   \n",
       "5  04/01/2025     99588   SO/24-25/80618         2296   \n",
       "\n",
       "                    customer_name       poc_name  poc_id    amount  discount  \\\n",
       "0  Anshu General Store Sector 34     Vikas Gupta       6  19125.00   1650.00   \n",
       "1                  bhai di rasoi   Abhay Srimali    7814   9670.48    735.48   \n",
       "3       Bikaner Sweets ( Harola )      Swatantra      25   4520.00    420.00   \n",
       "4            Lucknow kirana store      Raj Kumar    7039   1700.00      0.00   \n",
       "5            Champaran Meat House     Ajay Singh      38   5074.00    214.00   \n",
       "\n",
       "   net_order_amount  profit order_status warehouse_name  warehouse_id  \n",
       "0           17475.0     0.0       CLOSED          Noida             3  \n",
       "1            8935.0   -56.4       CLOSED  Greater NOIDA             6  \n",
       "3            4100.0    40.0       CLOSED          Noida             3  \n",
       "4            1700.0   -88.0       CLOSED    Gomti Nagar             1  \n",
       "5            4860.0    10.0       CLOSED       Telibagh             2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03d94331",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T21:29:45.801120Z",
     "iopub.status.busy": "2025-04-17T21:29:45.800923Z",
     "iopub.status.idle": "2025-04-17T21:29:45.808617Z",
     "shell.execute_reply": "2025-04-17T21:29:45.807766Z"
    },
    "papermill": {
     "duration": 0.01306,
     "end_time": "2025-04-17T21:29:45.809743",
     "exception": false,
     "start_time": "2025-04-17T21:29:45.796683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/404819675.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data.drop(['order_number','customer_name','poc_name','poc_id','amount','profit','order_status','warehouse_id'],axis=1,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "train_data.drop(['order_number','customer_name','poc_name','poc_id','amount','profit','order_status','warehouse_id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a938d1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T21:29:45.818101Z",
     "iopub.status.busy": "2025-04-17T21:29:45.817927Z",
     "iopub.status.idle": "2025-04-17T21:29:45.911093Z",
     "shell.execute_reply": "2025-04-17T21:29:45.910298Z"
    },
    "papermill": {
     "duration": 0.099013,
     "end_time": "2025-04-17T21:29:45.912499",
     "exception": false,
     "start_time": "2025-04-17T21:29:45.813486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>daily_order_count</th>\n",
       "      <th>discount</th>\n",
       "      <th>net_order_amount</th>\n",
       "      <th>warehouse_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4710.0</td>\n",
       "      <td>Telibagh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-10-06</td>\n",
       "      <td>1</td>\n",
       "      <td>120.00</td>\n",
       "      <td>2220.0</td>\n",
       "      <td>Telibagh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-10-07</td>\n",
       "      <td>1</td>\n",
       "      <td>150.00</td>\n",
       "      <td>12900.0</td>\n",
       "      <td>Telibagh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-10-09</td>\n",
       "      <td>1</td>\n",
       "      <td>200.00</td>\n",
       "      <td>3210.0</td>\n",
       "      <td>Telibagh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-10-10</td>\n",
       "      <td>1</td>\n",
       "      <td>273.76</td>\n",
       "      <td>5580.0</td>\n",
       "      <td>Telibagh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50025</th>\n",
       "      <td>9158</td>\n",
       "      <td>2025-04-03</td>\n",
       "      <td>1</td>\n",
       "      <td>540.00</td>\n",
       "      <td>6300.0</td>\n",
       "      <td>Greater NOIDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50026</th>\n",
       "      <td>9158</td>\n",
       "      <td>2025-04-07</td>\n",
       "      <td>1</td>\n",
       "      <td>530.00</td>\n",
       "      <td>6450.0</td>\n",
       "      <td>Greater NOIDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50027</th>\n",
       "      <td>9158</td>\n",
       "      <td>2025-04-08</td>\n",
       "      <td>1</td>\n",
       "      <td>481.00</td>\n",
       "      <td>5890.0</td>\n",
       "      <td>Greater NOIDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50028</th>\n",
       "      <td>9158</td>\n",
       "      <td>2025-04-09</td>\n",
       "      <td>1</td>\n",
       "      <td>721.00</td>\n",
       "      <td>8650.0</td>\n",
       "      <td>Greater NOIDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50029</th>\n",
       "      <td>9158</td>\n",
       "      <td>2025-04-10</td>\n",
       "      <td>1</td>\n",
       "      <td>710.00</td>\n",
       "      <td>8630.0</td>\n",
       "      <td>Greater NOIDA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50030 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       customer_id order_date  daily_order_count  discount  net_order_amount  \\\n",
       "0                1 2024-10-01                  1      0.00            4710.0   \n",
       "1                1 2024-10-06                  1    120.00            2220.0   \n",
       "2                1 2024-10-07                  1    150.00           12900.0   \n",
       "3                1 2024-10-09                  1    200.00            3210.0   \n",
       "4                1 2024-10-10                  1    273.76            5580.0   \n",
       "...            ...        ...                ...       ...               ...   \n",
       "50025         9158 2025-04-03                  1    540.00            6300.0   \n",
       "50026         9158 2025-04-07                  1    530.00            6450.0   \n",
       "50027         9158 2025-04-08                  1    481.00            5890.0   \n",
       "50028         9158 2025-04-09                  1    721.00            8650.0   \n",
       "50029         9158 2025-04-10                  1    710.00            8630.0   \n",
       "\n",
       "      warehouse_name  \n",
       "0           Telibagh  \n",
       "1           Telibagh  \n",
       "2           Telibagh  \n",
       "3           Telibagh  \n",
       "4           Telibagh  \n",
       "...              ...  \n",
       "50025  Greater NOIDA  \n",
       "50026  Greater NOIDA  \n",
       "50027  Greater NOIDA  \n",
       "50028  Greater NOIDA  \n",
       "50029  Greater NOIDA  \n",
       "\n",
       "[50030 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# assume train_data is your original DataFrame\n",
    "df = train_data.copy()\n",
    "df['order_date'] = pd.to_datetime(df['order_date'], dayfirst=True)\n",
    "\n",
    "# group & aggregate:\n",
    "daily_df = df.groupby(['customer_id','order_date']).agg(\n",
    "    daily_order_count = ('order_id',       'count'),\n",
    "    discount          = ('discount',       'sum'),\n",
    "    net_order_amount  = ('net_order_amount','sum'),\n",
    "    warehouse_name    = ('warehouse_name', 'first')  # or use mode if you prefer\n",
    ").reset_index()\n",
    "\n",
    "# now daily_df has exactly one row per customer per date\n",
    "daily_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2de6d92f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T21:29:45.922129Z",
     "iopub.status.busy": "2025-04-17T21:29:45.921892Z",
     "iopub.status.idle": "2025-04-17T21:29:45.938084Z",
     "shell.execute_reply": "2025-04-17T21:29:45.937534Z"
    },
    "papermill": {
     "duration": 0.022243,
     "end_time": "2025-04-17T21:29:45.939276",
     "exception": false,
     "start_time": "2025-04-17T21:29:45.917033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "daily_df_dummy=pd.get_dummies(daily_df,columns=['warehouse_name'],dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a827a47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T21:29:45.949611Z",
     "iopub.status.busy": "2025-04-17T21:29:45.948974Z",
     "iopub.status.idle": "2025-04-17T21:29:45.952218Z",
     "shell.execute_reply": "2025-04-17T21:29:45.951675Z"
    },
    "papermill": {
     "duration": 0.009496,
     "end_time": "2025-04-17T21:29:45.953267",
     "exception": false,
     "start_time": "2025-04-17T21:29:45.943771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEQ_LEN = 30\n",
    "PRED_HORIZON = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a94be62f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T21:29:45.974768Z",
     "iopub.status.busy": "2025-04-17T21:29:45.974498Z",
     "iopub.status.idle": "2025-04-17T21:29:50.990788Z",
     "shell.execute_reply": "2025-04-17T21:29:50.989879Z"
    },
    "papermill": {
     "duration": 5.024139,
     "end_time": "2025-04-17T21:29:50.992099",
     "exception": false,
     "start_time": "2025-04-17T21:29:45.967960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1932/1932 [00:04<00:00, 439.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (180411, 30, 16)\n",
      "y shape: (180411, 14)\n"
     ]
    }
   ],
   "source": [
    "df = daily_df_dummy.copy()\n",
    "df['order_date'] = pd.to_datetime(df['order_date'])\n",
    "\n",
    "# Add 'day_of_week' column\n",
    "df['day_of_week'] = df['order_date'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "\n",
    "# One-hot encode 'day_of_week'\n",
    "df = pd.get_dummies(df, columns=['day_of_week'], prefix='dow',dtype='int')\n",
    "\n",
    "# Identify feature columns (exclude ID/date)\n",
    "feature_cols = [c for c in df.columns \n",
    "                if c not in ('customer_id', 'order_date')]\n",
    "\n",
    "# Containers for sequence data\n",
    "X, y = [], []\n",
    "\n",
    "for cust_id, group in tqdm(df.groupby('customer_id'), total=df['customer_id'].nunique()):\n",
    "    group = group.set_index('order_date').sort_index()\n",
    "    full_idx = pd.date_range(group.index.min(), group.index.max(), freq='D')\n",
    "    group = group.reindex(full_idx).fillna(0)\n",
    "    \n",
    "    # keep customer_id and date\n",
    "    group['customer_id'] = cust_id\n",
    "    group['date'] = group.index\n",
    "    \n",
    "    data = group[feature_cols].values\n",
    "    targets = (group['daily_order_count'] > 0).astype(int).values\n",
    "\n",
    "    n = len(group)\n",
    "    for start in range(n - SEQ_LEN - PRED_HORIZON + 1):\n",
    "        end = start + SEQ_LEN\n",
    "        fend = end + PRED_HORIZON\n",
    "        \n",
    "        X.append(data[start:end, :])     # shape: (30, num_features)\n",
    "        y.append(targets[end:fend])      # shape: (14,)\n",
    "\n",
    "X = np.stack(X)\n",
    "y = np.stack(y)\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31aa8144",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T21:29:51.005628Z",
     "iopub.status.busy": "2025-04-17T21:29:51.005393Z",
     "iopub.status.idle": "2025-04-17T21:29:51.009859Z",
     "shell.execute_reply": "2025-04-17T21:29:51.009315Z"
    },
    "papermill": {
     "duration": 0.012056,
     "end_time": "2025-04-17T21:29:51.010830",
     "exception": false,
     "start_time": "2025-04-17T21:29:50.998774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def binary_focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def focal_loss(y_true, y_pred):\n",
    "        # Clip the predictions to prevent log(0) error\n",
    "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1 - 1e-7)\n",
    "        \n",
    "        # Calculate cross-entropy\n",
    "        ce = tf.keras.backend.binary_crossentropy(y_true, y_pred)\n",
    "        \n",
    "        # Calculate p_t\n",
    "        p_t = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
    "        \n",
    "        # Modulating factor\n",
    "        modulating_factor = tf.pow(1.0 - p_t, gamma)\n",
    "        \n",
    "        # Alpha factor\n",
    "        alpha_weight = y_true * alpha + (1 - y_true) * (1 - alpha)\n",
    "        \n",
    "        # Focal Loss\n",
    "        focal_loss = alpha_weight * modulating_factor * ce\n",
    "        return tf.reduce_mean(focal_loss)\n",
    "    \n",
    "    return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4393c004",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T21:29:51.023450Z",
     "iopub.status.busy": "2025-04-17T21:29:51.022965Z",
     "iopub.status.idle": "2025-04-17T21:29:51.375305Z",
     "shell.execute_reply": "2025-04-17T21:29:51.374640Z"
    },
    "papermill": {
     "duration": 0.359929,
     "end_time": "2025-04-17T21:29:51.376663",
     "exception": false,
     "start_time": "2025-04-17T21:29:51.016734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,y,test_size=0.4,random_state=42)\n",
    "X_cv,X_test,Y_cv,Y_test=train_test_split(X_test,Y_test,test_size=0.5,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90f48815",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T21:29:51.389536Z",
     "iopub.status.busy": "2025-04-17T21:29:51.389302Z",
     "iopub.status.idle": "2025-04-17T21:29:51.882295Z",
     "shell.execute_reply": "2025-04-17T21:29:51.881705Z"
    },
    "papermill": {
     "duration": 0.501006,
     "end_time": "2025-04-17T21:29:51.883795",
     "exception": false,
     "start_time": "2025-04-17T21:29:51.382789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "weights = compute_class_weight(class_weight='balanced',\n",
    "                                classes=[0,1],\n",
    "                                y=y.flatten())\n",
    "class_weight = {0: weights[0], 1: weights[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ff63d10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T21:29:51.897572Z",
     "iopub.status.busy": "2025-04-17T21:29:51.897303Z",
     "iopub.status.idle": "2025-04-17T21:29:51.904591Z",
     "shell.execute_reply": "2025-04-17T21:29:51.903886Z"
    },
    "papermill": {
     "duration": 0.015386,
     "end_time": "2025-04-17T21:29:51.905882",
     "exception": false,
     "start_time": "2025-04-17T21:29:51.890496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "faadceca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T21:29:51.918861Z",
     "iopub.status.busy": "2025-04-17T21:29:51.918421Z",
     "iopub.status.idle": "2025-04-17T21:29:56.436884Z",
     "shell.execute_reply": "2025-04-17T21:29:56.436162Z"
    },
    "papermill": {
     "duration": 4.52609,
     "end_time": "2025-04-17T21:29:56.438016",
     "exception": false,
     "start_time": "2025-04-17T21:29:51.911926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1744925394.477227      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1744925394.477853      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n",
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">74,240</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">462</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │          \u001b[38;5;34m74,240\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m49,408\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                  │             \u001b[38;5;34m462\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">126,190</span> (492.93 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m126,190\u001b[0m (492.93 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">126,190</span> (492.93 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m126,190\u001b[0m (492.93 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Assuming you have already defined:\n",
    "# SEQ_LEN = 30\n",
    "# PRED_HORIZON = 14\n",
    "# feature_cols = [...]  # list of your input column names\n",
    "\n",
    "NUM_FEATURES = len(feature_cols)\n",
    "\n",
    "model = Sequential([\n",
    "    # 1st LSTM layer, returns sequences so we can stack another LSTM\n",
    "    LSTM(128, input_shape=(SEQ_LEN, NUM_FEATURES), return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    # 2nd LSTM layer\n",
    "    LSTM(64, return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    # Dense “bottleneck” to learn combined features\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "\n",
    "    # Final output: 14 sigmoid neurons, one per future day\n",
    "    Dense(PRED_HORIZON, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss=binary_focal_loss(gamma=2.0, alpha=0.25),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56f25d47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T21:29:56.453147Z",
     "iopub.status.busy": "2025-04-17T21:29:56.452699Z",
     "iopub.status.idle": "2025-04-17T21:29:56.456355Z",
     "shell.execute_reply": "2025-04-17T21:29:56.455612Z"
    },
    "papermill": {
     "duration": 0.012571,
     "end_time": "2025-04-17T21:29:56.457392",
     "exception": false,
     "start_time": "2025-04-17T21:29:56.444821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='best_model.weights.h5',      # Path to save the model weights\n",
    "    monitor='val_loss',                    # Metric to monitor\n",
    "    save_best_only=True,                   # Save only the best weights\n",
    "    save_weights_only=True,                # Save only weights (not full model)\n",
    "    mode='min',                            # 'min' for loss, 'max' for accuracy\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17e1b89a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T21:29:56.471027Z",
     "iopub.status.busy": "2025-04-17T21:29:56.470623Z",
     "iopub.status.idle": "2025-04-17T21:52:53.694001Z",
     "shell.execute_reply": "2025-04-17T21:52:53.693379Z"
    },
    "papermill": {
     "duration": 1377.231538,
     "end_time": "2025-04-17T21:52:53.695239",
     "exception": false,
     "start_time": "2025-04-17T21:29:56.463701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1744925401.455121      62 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1361 - loss: 0.0667\n",
      "Epoch 1: val_loss improved from inf to 0.04249, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.1360 - loss: 0.0667 - val_accuracy: 0.2481 - val_loss: 0.0425\n",
      "Epoch 2/100\n",
      "\u001b[1m1687/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0703 - loss: 0.0497\n",
      "Epoch 2: val_loss improved from 0.04249 to 0.04241, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.0703 - loss: 0.0497 - val_accuracy: 0.1133 - val_loss: 0.0424\n",
      "Epoch 3/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0628 - loss: 0.0486\n",
      "Epoch 3: val_loss improved from 0.04241 to 0.04236, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.0628 - loss: 0.0486 - val_accuracy: 0.0627 - val_loss: 0.0424\n",
      "Epoch 4/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0609 - loss: 0.0479\n",
      "Epoch 4: val_loss improved from 0.04236 to 0.04234, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.0609 - loss: 0.0479 - val_accuracy: 0.0819 - val_loss: 0.0423\n",
      "Epoch 5/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0608 - loss: 0.0479\n",
      "Epoch 5: val_loss did not improve from 0.04234\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.0608 - loss: 0.0479 - val_accuracy: 0.1436 - val_loss: 0.0423\n",
      "Epoch 6/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0662 - loss: 0.0479\n",
      "Epoch 6: val_loss improved from 0.04234 to 0.04234, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.0661 - loss: 0.0479 - val_accuracy: 0.0535 - val_loss: 0.0423\n",
      "Epoch 7/100\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0606 - loss: 0.0480\n",
      "Epoch 7: val_loss improved from 0.04234 to 0.04232, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.0606 - loss: 0.0480 - val_accuracy: 0.0431 - val_loss: 0.0423\n",
      "Epoch 8/100\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0587 - loss: 0.0475\n",
      "Epoch 8: val_loss improved from 0.04232 to 0.04232, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.0587 - loss: 0.0475 - val_accuracy: 0.0392 - val_loss: 0.0423\n",
      "Epoch 9/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0639 - loss: 0.0475\n",
      "Epoch 9: val_loss improved from 0.04232 to 0.04231, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.0639 - loss: 0.0475 - val_accuracy: 0.0538 - val_loss: 0.0423\n",
      "Epoch 10/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0695 - loss: 0.0476\n",
      "Epoch 10: val_loss improved from 0.04231 to 0.04229, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.0694 - loss: 0.0476 - val_accuracy: 0.0407 - val_loss: 0.0423\n",
      "Epoch 11/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0630 - loss: 0.0475\n",
      "Epoch 11: val_loss improved from 0.04229 to 0.04228, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.0630 - loss: 0.0475 - val_accuracy: 0.0357 - val_loss: 0.0423\n",
      "Epoch 12/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0653 - loss: 0.0472\n",
      "Epoch 12: val_loss did not improve from 0.04228\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.0654 - loss: 0.0472 - val_accuracy: 0.0793 - val_loss: 0.0423\n",
      "Epoch 13/100\n",
      "\u001b[1m1685/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0804 - loss: 0.0475\n",
      "Epoch 13: val_loss improved from 0.04228 to 0.04228, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.0804 - loss: 0.0475 - val_accuracy: 0.0734 - val_loss: 0.0423\n",
      "Epoch 14/100\n",
      "\u001b[1m1686/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0879 - loss: 0.0474\n",
      "Epoch 14: val_loss did not improve from 0.04228\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.0879 - loss: 0.0474 - val_accuracy: 0.1314 - val_loss: 0.0423\n",
      "Epoch 15/100\n",
      "\u001b[1m1690/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1030 - loss: 0.0472\n",
      "Epoch 15: val_loss improved from 0.04228 to 0.04227, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1030 - loss: 0.0472 - val_accuracy: 0.1045 - val_loss: 0.0423\n",
      "Epoch 16/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1042 - loss: 0.0474\n",
      "Epoch 16: val_loss did not improve from 0.04227\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1042 - loss: 0.0474 - val_accuracy: 0.0885 - val_loss: 0.0423\n",
      "Epoch 17/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1114 - loss: 0.0473\n",
      "Epoch 17: val_loss did not improve from 0.04227\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1114 - loss: 0.0473 - val_accuracy: 0.1058 - val_loss: 0.0423\n",
      "Epoch 18/100\n",
      "\u001b[1m1687/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1158 - loss: 0.0471\n",
      "Epoch 18: val_loss improved from 0.04227 to 0.04226, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.1158 - loss: 0.0471 - val_accuracy: 0.1496 - val_loss: 0.0423\n",
      "Epoch 19/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1285 - loss: 0.0472\n",
      "Epoch 19: val_loss improved from 0.04226 to 0.04224, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1284 - loss: 0.0472 - val_accuracy: 0.1757 - val_loss: 0.0422\n",
      "Epoch 20/100\n",
      "\u001b[1m1690/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1381 - loss: 0.0473\n",
      "Epoch 20: val_loss improved from 0.04224 to 0.04224, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1381 - loss: 0.0473 - val_accuracy: 0.1584 - val_loss: 0.0422\n",
      "Epoch 21/100\n",
      "\u001b[1m1690/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1322 - loss: 0.0473\n",
      "Epoch 21: val_loss did not improve from 0.04224\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1322 - loss: 0.0473 - val_accuracy: 0.1736 - val_loss: 0.0422\n",
      "Epoch 22/100\n",
      "\u001b[1m1686/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1384 - loss: 0.0470\n",
      "Epoch 22: val_loss improved from 0.04224 to 0.04223, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1384 - loss: 0.0470 - val_accuracy: 0.1445 - val_loss: 0.0422\n",
      "Epoch 23/100\n",
      "\u001b[1m1686/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1372 - loss: 0.0475\n",
      "Epoch 23: val_loss did not improve from 0.04223\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1372 - loss: 0.0475 - val_accuracy: 0.1605 - val_loss: 0.0422\n",
      "Epoch 24/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1397 - loss: 0.0471\n",
      "Epoch 24: val_loss did not improve from 0.04223\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.1397 - loss: 0.0471 - val_accuracy: 0.1445 - val_loss: 0.0422\n",
      "Epoch 25/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1439 - loss: 0.0469\n",
      "Epoch 25: val_loss did not improve from 0.04223\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1439 - loss: 0.0469 - val_accuracy: 0.1460 - val_loss: 0.0422\n",
      "Epoch 26/100\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1345 - loss: 0.0470\n",
      "Epoch 26: val_loss improved from 0.04223 to 0.04222, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1345 - loss: 0.0470 - val_accuracy: 0.1436 - val_loss: 0.0422\n",
      "Epoch 27/100\n",
      "\u001b[1m1687/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1444 - loss: 0.0471\n",
      "Epoch 27: val_loss improved from 0.04222 to 0.04222, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1444 - loss: 0.0471 - val_accuracy: 0.1678 - val_loss: 0.0422\n",
      "Epoch 28/100\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1400 - loss: 0.0469\n",
      "Epoch 28: val_loss did not improve from 0.04222\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1400 - loss: 0.0469 - val_accuracy: 0.1487 - val_loss: 0.0422\n",
      "Epoch 29/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1369 - loss: 0.0471\n",
      "Epoch 29: val_loss did not improve from 0.04222\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1369 - loss: 0.0471 - val_accuracy: 0.1503 - val_loss: 0.0422\n",
      "Epoch 30/100\n",
      "\u001b[1m1690/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1464 - loss: 0.0471\n",
      "Epoch 30: val_loss improved from 0.04222 to 0.04221, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1463 - loss: 0.0471 - val_accuracy: 0.1531 - val_loss: 0.0422\n",
      "Epoch 31/100\n",
      "\u001b[1m1687/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1391 - loss: 0.0471\n",
      "Epoch 31: val_loss did not improve from 0.04221\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1391 - loss: 0.0471 - val_accuracy: 0.1579 - val_loss: 0.0422\n",
      "Epoch 32/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1496 - loss: 0.0472\n",
      "Epoch 32: val_loss improved from 0.04221 to 0.04219, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.1496 - loss: 0.0472 - val_accuracy: 0.1359 - val_loss: 0.0422\n",
      "Epoch 33/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1406 - loss: 0.0470\n",
      "Epoch 33: val_loss did not improve from 0.04219\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1406 - loss: 0.0470 - val_accuracy: 0.1476 - val_loss: 0.0422\n",
      "Epoch 34/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1437 - loss: 0.0470\n",
      "Epoch 34: val_loss did not improve from 0.04219\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.1437 - loss: 0.0470 - val_accuracy: 0.1290 - val_loss: 0.0422\n",
      "Epoch 35/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1460 - loss: 0.0469\n",
      "Epoch 35: val_loss did not improve from 0.04219\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1460 - loss: 0.0469 - val_accuracy: 0.1369 - val_loss: 0.0422\n",
      "Epoch 36/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1479 - loss: 0.0468\n",
      "Epoch 36: val_loss did not improve from 0.04219\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1479 - loss: 0.0468 - val_accuracy: 0.1408 - val_loss: 0.0422\n",
      "Epoch 37/100\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1512 - loss: 0.0469\n",
      "Epoch 37: val_loss did not improve from 0.04219\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1512 - loss: 0.0469 - val_accuracy: 0.1559 - val_loss: 0.0422\n",
      "Epoch 38/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1465 - loss: 0.0471\n",
      "Epoch 38: val_loss improved from 0.04219 to 0.04218, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1465 - loss: 0.0471 - val_accuracy: 0.1310 - val_loss: 0.0422\n",
      "Epoch 39/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1426 - loss: 0.0472\n",
      "Epoch 39: val_loss did not improve from 0.04218\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1426 - loss: 0.0472 - val_accuracy: 0.1273 - val_loss: 0.0422\n",
      "Epoch 40/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1500 - loss: 0.0470\n",
      "Epoch 40: val_loss did not improve from 0.04218\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1500 - loss: 0.0470 - val_accuracy: 0.1266 - val_loss: 0.0422\n",
      "Epoch 41/100\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1368 - loss: 0.0471\n",
      "Epoch 41: val_loss did not improve from 0.04218\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1368 - loss: 0.0471 - val_accuracy: 0.1412 - val_loss: 0.0422\n",
      "Epoch 42/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1443 - loss: 0.0469\n",
      "Epoch 42: val_loss improved from 0.04218 to 0.04215, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1443 - loss: 0.0469 - val_accuracy: 0.1334 - val_loss: 0.0421\n",
      "Epoch 43/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1401 - loss: 0.0468\n",
      "Epoch 43: val_loss improved from 0.04215 to 0.04214, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1401 - loss: 0.0468 - val_accuracy: 0.1468 - val_loss: 0.0421\n",
      "Epoch 44/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1511 - loss: 0.0468\n",
      "Epoch 44: val_loss did not improve from 0.04214\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1511 - loss: 0.0468 - val_accuracy: 0.1350 - val_loss: 0.0422\n",
      "Epoch 45/100\n",
      "\u001b[1m1685/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1484 - loss: 0.0470\n",
      "Epoch 45: val_loss did not improve from 0.04214\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1484 - loss: 0.0470 - val_accuracy: 0.1339 - val_loss: 0.0422\n",
      "Epoch 46/100\n",
      "\u001b[1m1687/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1418 - loss: 0.0469\n",
      "Epoch 46: val_loss did not improve from 0.04214\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.1418 - loss: 0.0469 - val_accuracy: 0.1307 - val_loss: 0.0422\n",
      "Epoch 47/100\n",
      "\u001b[1m1690/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1485 - loss: 0.0471\n",
      "Epoch 47: val_loss improved from 0.04214 to 0.04213, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1485 - loss: 0.0471 - val_accuracy: 0.1360 - val_loss: 0.0421\n",
      "Epoch 48/100\n",
      "\u001b[1m1686/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1440 - loss: 0.0469\n",
      "Epoch 48: val_loss did not improve from 0.04213\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.1440 - loss: 0.0469 - val_accuracy: 0.1433 - val_loss: 0.0421\n",
      "Epoch 49/100\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1418 - loss: 0.0468\n",
      "Epoch 49: val_loss did not improve from 0.04213\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1418 - loss: 0.0468 - val_accuracy: 0.1426 - val_loss: 0.0421\n",
      "Epoch 50/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1507 - loss: 0.0468\n",
      "Epoch 50: val_loss improved from 0.04213 to 0.04212, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1507 - loss: 0.0468 - val_accuracy: 0.1342 - val_loss: 0.0421\n",
      "Epoch 51/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1439 - loss: 0.0471\n",
      "Epoch 51: val_loss improved from 0.04212 to 0.04210, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1439 - loss: 0.0471 - val_accuracy: 0.1454 - val_loss: 0.0421\n",
      "Epoch 52/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1461 - loss: 0.0471\n",
      "Epoch 52: val_loss did not improve from 0.04210\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.1461 - loss: 0.0470 - val_accuracy: 0.1425 - val_loss: 0.0422\n",
      "Epoch 53/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1456 - loss: 0.0473\n",
      "Epoch 53: val_loss improved from 0.04210 to 0.04210, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1456 - loss: 0.0473 - val_accuracy: 0.1445 - val_loss: 0.0421\n",
      "Epoch 54/100\n",
      "\u001b[1m1685/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1443 - loss: 0.0468\n",
      "Epoch 54: val_loss did not improve from 0.04210\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1443 - loss: 0.0468 - val_accuracy: 0.1449 - val_loss: 0.0421\n",
      "Epoch 55/100\n",
      "\u001b[1m1690/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1456 - loss: 0.0468\n",
      "Epoch 55: val_loss improved from 0.04210 to 0.04209, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1456 - loss: 0.0468 - val_accuracy: 0.1577 - val_loss: 0.0421\n",
      "Epoch 56/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1517 - loss: 0.0469\n",
      "Epoch 56: val_loss did not improve from 0.04209\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1517 - loss: 0.0469 - val_accuracy: 0.1248 - val_loss: 0.0421\n",
      "Epoch 57/100\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1436 - loss: 0.0467\n",
      "Epoch 57: val_loss improved from 0.04209 to 0.04206, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1436 - loss: 0.0467 - val_accuracy: 0.1567 - val_loss: 0.0421\n",
      "Epoch 58/100\n",
      "\u001b[1m1685/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1536 - loss: 0.0468\n",
      "Epoch 58: val_loss did not improve from 0.04206\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1536 - loss: 0.0468 - val_accuracy: 0.1333 - val_loss: 0.0421\n",
      "Epoch 59/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1428 - loss: 0.0469\n",
      "Epoch 59: val_loss did not improve from 0.04206\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1428 - loss: 0.0469 - val_accuracy: 0.1315 - val_loss: 0.0421\n",
      "Epoch 60/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1437 - loss: 0.0466\n",
      "Epoch 60: val_loss did not improve from 0.04206\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1437 - loss: 0.0466 - val_accuracy: 0.1476 - val_loss: 0.0421\n",
      "Epoch 61/100\n",
      "\u001b[1m1690/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1418 - loss: 0.0466\n",
      "Epoch 61: val_loss improved from 0.04206 to 0.04204, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1418 - loss: 0.0466 - val_accuracy: 0.1462 - val_loss: 0.0420\n",
      "Epoch 62/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1502 - loss: 0.0466\n",
      "Epoch 62: val_loss improved from 0.04204 to 0.04203, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1502 - loss: 0.0466 - val_accuracy: 0.1261 - val_loss: 0.0420\n",
      "Epoch 63/100\n",
      "\u001b[1m1690/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1418 - loss: 0.0469\n",
      "Epoch 63: val_loss did not improve from 0.04203\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1418 - loss: 0.0469 - val_accuracy: 0.1460 - val_loss: 0.0420\n",
      "Epoch 64/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1524 - loss: 0.0468\n",
      "Epoch 64: val_loss did not improve from 0.04203\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1524 - loss: 0.0468 - val_accuracy: 0.1289 - val_loss: 0.0420\n",
      "Epoch 65/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1452 - loss: 0.0468\n",
      "Epoch 65: val_loss improved from 0.04203 to 0.04201, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1452 - loss: 0.0468 - val_accuracy: 0.1433 - val_loss: 0.0420\n",
      "Epoch 66/100\n",
      "\u001b[1m1690/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1441 - loss: 0.0467\n",
      "Epoch 66: val_loss did not improve from 0.04201\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1441 - loss: 0.0467 - val_accuracy: 0.1267 - val_loss: 0.0420\n",
      "Epoch 67/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1458 - loss: 0.0465\n",
      "Epoch 67: val_loss did not improve from 0.04201\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1458 - loss: 0.0465 - val_accuracy: 0.1282 - val_loss: 0.0420\n",
      "Epoch 68/100\n",
      "\u001b[1m1687/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1420 - loss: 0.0465\n",
      "Epoch 68: val_loss improved from 0.04201 to 0.04197, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.1420 - loss: 0.0465 - val_accuracy: 0.1346 - val_loss: 0.0420\n",
      "Epoch 69/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1452 - loss: 0.0468\n",
      "Epoch 69: val_loss did not improve from 0.04197\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1452 - loss: 0.0468 - val_accuracy: 0.1438 - val_loss: 0.0420\n",
      "Epoch 70/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1576 - loss: 0.0466\n",
      "Epoch 70: val_loss improved from 0.04197 to 0.04197, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1576 - loss: 0.0466 - val_accuracy: 0.1366 - val_loss: 0.0420\n",
      "Epoch 71/100\n",
      "\u001b[1m1685/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1438 - loss: 0.0466\n",
      "Epoch 71: val_loss did not improve from 0.04197\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1438 - loss: 0.0466 - val_accuracy: 0.1523 - val_loss: 0.0420\n",
      "Epoch 72/100\n",
      "\u001b[1m1687/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1470 - loss: 0.0465\n",
      "Epoch 72: val_loss improved from 0.04197 to 0.04196, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1470 - loss: 0.0465 - val_accuracy: 0.1423 - val_loss: 0.0420\n",
      "Epoch 73/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1470 - loss: 0.0466\n",
      "Epoch 73: val_loss improved from 0.04196 to 0.04195, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1471 - loss: 0.0466 - val_accuracy: 0.1644 - val_loss: 0.0420\n",
      "Epoch 74/100\n",
      "\u001b[1m1685/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1557 - loss: 0.0464\n",
      "Epoch 74: val_loss improved from 0.04195 to 0.04191, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1556 - loss: 0.0464 - val_accuracy: 0.1406 - val_loss: 0.0419\n",
      "Epoch 75/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1454 - loss: 0.0466\n",
      "Epoch 75: val_loss did not improve from 0.04191\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.1454 - loss: 0.0466 - val_accuracy: 0.1376 - val_loss: 0.0419\n",
      "Epoch 76/100\n",
      "\u001b[1m1690/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1495 - loss: 0.0467\n",
      "Epoch 76: val_loss improved from 0.04191 to 0.04188, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1495 - loss: 0.0467 - val_accuracy: 0.1479 - val_loss: 0.0419\n",
      "Epoch 77/100\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1483 - loss: 0.0466\n",
      "Epoch 77: val_loss did not improve from 0.04188\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1483 - loss: 0.0466 - val_accuracy: 0.1287 - val_loss: 0.0419\n",
      "Epoch 78/100\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1432 - loss: 0.0465\n",
      "Epoch 78: val_loss improved from 0.04188 to 0.04188, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.1432 - loss: 0.0465 - val_accuracy: 0.1361 - val_loss: 0.0419\n",
      "Epoch 79/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1495 - loss: 0.0467\n",
      "Epoch 79: val_loss improved from 0.04188 to 0.04187, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1495 - loss: 0.0467 - val_accuracy: 0.1403 - val_loss: 0.0419\n",
      "Epoch 80/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1444 - loss: 0.0464\n",
      "Epoch 80: val_loss improved from 0.04187 to 0.04186, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.1444 - loss: 0.0464 - val_accuracy: 0.1442 - val_loss: 0.0419\n",
      "Epoch 81/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1443 - loss: 0.0466\n",
      "Epoch 81: val_loss improved from 0.04186 to 0.04186, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1443 - loss: 0.0466 - val_accuracy: 0.1409 - val_loss: 0.0419\n",
      "Epoch 82/100\n",
      "\u001b[1m1686/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1475 - loss: 0.0464\n",
      "Epoch 82: val_loss improved from 0.04186 to 0.04183, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.1475 - loss: 0.0464 - val_accuracy: 0.1307 - val_loss: 0.0418\n",
      "Epoch 83/100\n",
      "\u001b[1m1685/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1397 - loss: 0.0464\n",
      "Epoch 83: val_loss improved from 0.04183 to 0.04183, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1397 - loss: 0.0464 - val_accuracy: 0.1442 - val_loss: 0.0418\n",
      "Epoch 84/100\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1500 - loss: 0.0465\n",
      "Epoch 84: val_loss improved from 0.04183 to 0.04179, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1500 - loss: 0.0465 - val_accuracy: 0.1236 - val_loss: 0.0418\n",
      "Epoch 85/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1381 - loss: 0.0464\n",
      "Epoch 85: val_loss did not improve from 0.04179\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1381 - loss: 0.0464 - val_accuracy: 0.1378 - val_loss: 0.0418\n",
      "Epoch 86/100\n",
      "\u001b[1m1690/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1429 - loss: 0.0464\n",
      "Epoch 86: val_loss did not improve from 0.04179\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1429 - loss: 0.0464 - val_accuracy: 0.1401 - val_loss: 0.0418\n",
      "Epoch 87/100\n",
      "\u001b[1m1686/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1496 - loss: 0.0462\n",
      "Epoch 87: val_loss improved from 0.04179 to 0.04177, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1495 - loss: 0.0462 - val_accuracy: 0.1303 - val_loss: 0.0418\n",
      "Epoch 88/100\n",
      "\u001b[1m1690/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1360 - loss: 0.0464\n",
      "Epoch 88: val_loss did not improve from 0.04177\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.1360 - loss: 0.0464 - val_accuracy: 0.1449 - val_loss: 0.0418\n",
      "Epoch 89/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1436 - loss: 0.0465\n",
      "Epoch 89: val_loss improved from 0.04177 to 0.04176, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1436 - loss: 0.0465 - val_accuracy: 0.1360 - val_loss: 0.0418\n",
      "Epoch 90/100\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1507 - loss: 0.0462\n",
      "Epoch 90: val_loss did not improve from 0.04176\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.1507 - loss: 0.0462 - val_accuracy: 0.1323 - val_loss: 0.0418\n",
      "Epoch 91/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1417 - loss: 0.0463\n",
      "Epoch 91: val_loss improved from 0.04176 to 0.04173, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1417 - loss: 0.0463 - val_accuracy: 0.1447 - val_loss: 0.0417\n",
      "Epoch 92/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1442 - loss: 0.0463\n",
      "Epoch 92: val_loss improved from 0.04173 to 0.04172, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1442 - loss: 0.0463 - val_accuracy: 0.1378 - val_loss: 0.0417\n",
      "Epoch 93/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1474 - loss: 0.0462\n",
      "Epoch 93: val_loss improved from 0.04172 to 0.04169, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1474 - loss: 0.0462 - val_accuracy: 0.1419 - val_loss: 0.0417\n",
      "Epoch 94/100\n",
      "\u001b[1m1690/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1474 - loss: 0.0463\n",
      "Epoch 94: val_loss did not improve from 0.04169\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1474 - loss: 0.0463 - val_accuracy: 0.1328 - val_loss: 0.0417\n",
      "Epoch 95/100\n",
      "\u001b[1m1686/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1462 - loss: 0.0465\n",
      "Epoch 95: val_loss did not improve from 0.04169\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1462 - loss: 0.0465 - val_accuracy: 0.1476 - val_loss: 0.0417\n",
      "Epoch 96/100\n",
      "\u001b[1m1687/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1419 - loss: 0.0464\n",
      "Epoch 96: val_loss improved from 0.04169 to 0.04166, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.1419 - loss: 0.0464 - val_accuracy: 0.1435 - val_loss: 0.0417\n",
      "Epoch 97/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1436 - loss: 0.0462\n",
      "Epoch 97: val_loss improved from 0.04166 to 0.04162, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1436 - loss: 0.0462 - val_accuracy: 0.1528 - val_loss: 0.0416\n",
      "Epoch 98/100\n",
      "\u001b[1m1690/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1501 - loss: 0.0463\n",
      "Epoch 98: val_loss did not improve from 0.04162\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.1501 - loss: 0.0463 - val_accuracy: 0.1381 - val_loss: 0.0416\n",
      "Epoch 99/100\n",
      "\u001b[1m1687/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1548 - loss: 0.0461\n",
      "Epoch 99: val_loss improved from 0.04162 to 0.04161, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1548 - loss: 0.0461 - val_accuracy: 0.1295 - val_loss: 0.0416\n",
      "Epoch 100/100\n",
      "\u001b[1m1686/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1406 - loss: 0.0462\n",
      "Epoch 100: val_loss improved from 0.04161 to 0.04160, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1406 - loss: 0.0462 - val_accuracy: 0.1466 - val_loss: 0.0416\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, Y_train,\n",
    "    class_weight=class_weight,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_cv, Y_cv),\n",
    "    callbacks=[checkpoint]  # You can add ModelCheckpoint or EarlyStopping if needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "757358db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T21:52:55.794392Z",
     "iopub.status.busy": "2025-04-17T21:52:55.794066Z",
     "iopub.status.idle": "2025-04-17T21:52:56.176041Z",
     "shell.execute_reply": "2025-04-17T21:52:56.175287Z"
    },
    "papermill": {
     "duration": 1.419822,
     "end_time": "2025-04-17T21:52:56.177220",
     "exception": false,
     "start_time": "2025-04-17T21:52:54.757398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7af2f5c120d0>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "029ca6e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T21:52:58.263476Z",
     "iopub.status.busy": "2025-04-17T21:52:58.263149Z",
     "iopub.status.idle": "2025-04-17T21:53:16.648226Z",
     "shell.execute_reply": "2025-04-17T21:53:16.647383Z"
    },
    "papermill": {
     "duration": 19.431236,
     "end_time": "2025-04-17T21:53:16.649340",
     "exception": false,
     "start_time": "2025-04-17T21:52:57.218104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 22 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m3383/3383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "Training Data:\n",
      "Accuracy is  0.14414389446261294\n",
      "Precision is  0.867942830810005\n",
      "Recall is  0.043430748995048264\n",
      "F1 Score is  0.0826923071838493\n",
      "Validation Data:\n",
      "Accuracy is  0.14059641926722466\n",
      "Precision is  0.855365197427394\n",
      "Recall is  0.04706226023755923\n",
      "F1 Score is  0.08916737513053365\n",
      "Test Data:\n",
      "Accuracy is  0.1424216389989746\n",
      "Precision is  0.86082877217237\n",
      "Recall is  0.04350864596832844\n",
      "F1 Score is  0.0827895045269323\n"
     ]
    }
   ],
   "source": [
    "model_best = clone_model(model)\n",
    "\n",
    "# Important: you need to compile it again\n",
    "model_best.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# Load the best saved weights\n",
    "model_best.load_weights('best_model.weights.h5')\n",
    "pred_val=model_best.predict(X_cv)\n",
    "pred_val_bin= (pred_val > 0.5).astype(int)\n",
    "pred_train=model_best.predict(X_train)\n",
    "pred_train_bin= (pred_train> 0.5).astype(int)\n",
    "pred_test=model_best.predict(X_test)\n",
    "pred_test_bin= (pred_test> 0.5).astype(int)\n",
    "print(\"Training Data:\")\n",
    "\n",
    "print(\"Accuracy is \",accuracy_score(Y_train,pred_train_bin))\n",
    "print(\"Precision is \",precision_score(Y_train,pred_train_bin,average='macro'))\n",
    "print(\"Recall is \",recall_score(Y_train,pred_train_bin,average='macro'))\n",
    "print(\"F1 Score is \",f1_score(Y_train,pred_train_bin,average='macro'))\n",
    "\n",
    "print(\"Validation Data:\")\n",
    "\n",
    "print(\"Accuracy is \",accuracy_score(Y_cv,pred_val_bin))\n",
    "print(\"Precision is \",precision_score(Y_cv,pred_val_bin,average='macro'))\n",
    "print(\"Recall is \",recall_score(Y_cv,pred_val_bin,average='macro'))\n",
    "print(\"F1 Score is \",f1_score(Y_cv,pred_val_bin,average='macro'))\n",
    "\n",
    "print(\"Test Data:\")\n",
    "\n",
    "print(\"Accuracy is \",accuracy_score(Y_test,pred_test_bin))\n",
    "print(\"Precision is \",precision_score(Y_test,pred_test_bin,average='macro'))\n",
    "print(\"Recall is \",recall_score(Y_test,pred_test_bin,average='macro'))\n",
    "print(\"F1 Score is \",f1_score(Y_test,pred_test_bin,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bef9ec3",
   "metadata": {
    "papermill": {
     "duration": 1.02679,
     "end_time": "2025-04-17T21:53:18.666932",
     "exception": false,
     "start_time": "2025-04-17T21:53:17.640142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7141798,
     "sourceId": 11402349,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7154869,
     "sourceId": 11424360,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1448.283533,
   "end_time": "2025-04-17T21:53:22.749718",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-17T21:29:14.466185",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
